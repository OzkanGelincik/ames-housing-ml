{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project - Ames Housing Data\n",
    "\n",
    "Ames, Iowa is the college town of **Iowa State University**. The Ames housing dataset consists of about $2500$ house sale records between $2006-2010$. Detailed information about the house attributes, along with the sale prices, is recorded in the dataset. The goal of the project is to:\n",
    "- perform descriptive data analysis to gain business (i.e. housing market) insights\n",
    "- build descriptive machine learning models to understand the local housing market.\n",
    "- build predictive machine learning models for the local house price prediction.\n",
    "\n",
    "A subset of the **Ames** dataset is hosted on [**Kaggle**](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) as an entry-level regression competition. You may visit their site for some information on the meanings of its data columns (the data dictionary). In this notebook, we will describe various project ideas related to this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-Learn Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Tree Models\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Scikit-Learn Version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(f\"Notebook Scikit-Learn Version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from: /Users/ozkangelincik/git_proj/ames-housing-prices/data/Ames_Housing_Price_Data.csv\n",
      "(2580, 82)\n",
      "Data Loaded. Train Shape: (2064, 79)\n",
      "cast_to_str module: utils\n",
      "Training the Unified Production Pipeline (Raw Data -> Prediction)...\n",
      "âœ… Training Complete. Test R^2: 0.93176\n",
      "(This should match or slightly exceed your previous 0.933 score)\n",
      "âœ… Model saved to:   /Users/ozkangelincik/git_proj/ames-housing-prices/notebooks/models/ames_housing_super_model_production.pkl\n",
      "âœ… Columns saved to: /Users/ozkangelincik/git_proj/ames-housing-prices/notebooks/models/ames_model_columns.pkl\n",
      "   You can now restart app_3.0.py\n",
      "\n",
      "--- Simulating Production Inference ---\n",
      "Input: {'Neighborhood': 'CollgCr', 'LotArea': 9600, 'OverallQual': 7, 'YearBuilt': 2000, 'GrLivArea': 1700}\n",
      "Predicted Price: $160,803.77\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION & DATA LOADING\n",
    "# ==========================================\n",
    "\n",
    "# Define the columns (Manual Lists from your Lab Notebook)\n",
    "CATEGORICAL_COLS = [\n",
    "    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "    'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "    'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
    "    'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "    'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n",
    "    'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n",
    "    'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "    'MoSold', 'YrSold', 'SaleType', 'SaleCondition'\n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
    "    'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "    'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    "    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    "    'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n",
    "    'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "    'ScreenPorch', 'PoolArea', 'MiscVal'\n",
    "]\n",
    "\n",
    "# 1. Get the current working directory (where this notebook is)\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# 2. Define the path to the data file\n",
    "# If your notebook is in a subfolder (e.g., 'notebooks/'), use .parent to go up one level\n",
    "data_path = current_dir.parent / \"data\" / \"Ames_Housing_Price_Data.csv\"\n",
    "\n",
    "# Check if the file exists before loading (optional but helpful for debugging)\n",
    "if not data_path.exists():\n",
    "    # Fallback: Maybe the notebook IS in the root?\n",
    "    data_path = current_dir / \"data\" / \"Ames_Housing_Price_Data.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Quick check\n",
    "print(f\"Data loaded successfully from: {data_path}\")\n",
    "print(df.shape)\n",
    "\n",
    "# Basic Cleanup\n",
    "if 'PID' in df.columns:\n",
    "    df = df.drop(columns=['PID', 'Unnamed: 0'], errors='ignore')\n",
    "\n",
    "X = df.drop(columns=['SalePrice'])\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Split (We fit on Train to maintain validity of our 0.933 score)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Data Loaded. Train Shape: {X_train.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEFINE THE \"TRANSLATOR\" (Preprocessing)\n",
    "# ==========================================\n",
    "\n",
    "# HELPER FUNCTION IS DEPRICATED AND MOVED TO UTILS: dashboard.py used manual function (caused shiny deployment errors), dashboard_2.0.py used utils.py\n",
    "# Helper function to ensure everything is a string before imputation\n",
    "# def cast_to_str(x):\n",
    "#     return x.astype(str)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Get the current directory, then go to the parent (project root)\n",
    "# .resolve() ensures we have the absolute path\n",
    "project_root = Path.cwd().parent.resolve()\n",
    "\n",
    "# 2. Add it to sys.path if it isn't already there\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# 3. Now you can import\n",
    "from utils import cast_to_str\n",
    "\n",
    "print(f\"cast_to_str module: {cast_to_str.__module__}\")\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# A. Categorical Branch\n",
    "# 1. Force to String\n",
    "# 2. Fill Missing with 'None' (The \"Safety Net\")\n",
    "# 3. Ordinal Encode (Strings -> Integers like 0, 1, 2)\n",
    "#    Note: We use -1 for unknown categories so the model doesn't crash on new data\n",
    "cat_preprocessing = Pipeline([\n",
    "    ('caster', FunctionTransformer(cast_to_str, validate=False)),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# B. Numerical Branch\n",
    "# 1. Fill Missing with Median\n",
    "num_preprocessing = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# C. Global Preprocessor\n",
    "# This combines the two branches. \n",
    "# IMPORTANT: It outputs [Categorical_Cols, Numerical_Cols] in that order.\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessing, CATEGORICAL_COLS),\n",
    "    ('num', num_preprocessing, NUMERICAL_COLS)\n",
    "], verbose_feature_names_out=False)\n",
    "\n",
    "# ==========================================\n",
    "# 3. DEFINE THE \"BRAIN\" (Model Branches)\n",
    "# ==========================================\n",
    "\n",
    "# We need to calculate how many categorical columns we have.\n",
    "# This helps the Lasso branch know which columns to One-Hot Encode.\n",
    "n_cats = len(CATEGORICAL_COLS)\n",
    "\n",
    "# --- Branch A: Lasso ---\n",
    "# Input: [Ordinal_Ints, Floats]\n",
    "# Lasso needs One-Hot Encoding for Categories, but NOT for Numericals.\n",
    "# We use a sub-ColumnTransformer to apply OHE only to the first 'n_cats' columns.\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('prep', ColumnTransformer([\n",
    "        ('ohe', OneHotEncoder(categories='auto', sparse_output=False, handle_unknown='ignore'), slice(0, n_cats))\n",
    "    ], remainder='passthrough')), # Numerical columns pass through as-is\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Lasso(alpha=0.001, max_iter=50000, random_state=42))\n",
    "])\n",
    "\n",
    "# --- Branch B: XGBoost ---\n",
    "# XGBoost handles the [Ordinal_Ints, Floats] array natively.\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500, learning_rate=0.1, max_depth=3, subsample=0.8,\n",
    "    random_state=42, n_jobs=1\n",
    ")\n",
    "\n",
    "# --- Branch C: CatBoost ---\n",
    "# CatBoost handles the [Ordinal_Ints, Floats] array natively.\n",
    "cb_model = CatBoostRegressor(\n",
    "    iterations=1000, learning_rate=0.05, depth=4, l2_leaf_reg=3,\n",
    "    loss_function='RMSE', random_seed=42, verbose=0, allow_writing_files=False\n",
    ")\n",
    "\n",
    "# --- The Voting Ensemble ---\n",
    "voting_model = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('lasso', lasso_pipeline),\n",
    "        ('xgb', xgb_model),\n",
    "        ('catboost', cb_model)\n",
    "    ],\n",
    "    weights=[1, 2, 2],\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. THE \"GRAND PIPELINE\" (End-to-End)\n",
    "# ==========================================\n",
    "\n",
    "# We wrap the whole thing:\n",
    "# Raw Data -> Preprocessor -> LogTransform -> VotingModel -> InverseLog\n",
    "final_production_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', TransformedTargetRegressor(\n",
    "        regressor=voting_model,\n",
    "        func=np.log1p,\n",
    "        inverse_func=np.expm1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 5. TRAINING\n",
    "# ==========================================\n",
    "print(\"Training the Unified Production Pipeline (Raw Data -> Prediction)...\")\n",
    "# Notice we pass X_train (Raw), not X_train_ordinal!\n",
    "final_production_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Score\n",
    "score = final_production_pipeline.score(X_test, y_test)\n",
    "print(f\"âœ… Training Complete. Test R^2: {score:.5f}\")\n",
    "print(\"(This should match or slightly exceed your previous 0.933 score)\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. SAVE ARTIFACT (Production Ready)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Setup the Directory\n",
    "# This creates a 'models' folder in the same directory as the notebook\n",
    "MODEL_DIR = Path.cwd() / 'models'\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Define Paths\n",
    "model_path = MODEL_DIR / 'ames_housing_super_model_production.pkl'\n",
    "cols_path = MODEL_DIR / 'ames_model_columns.pkl'\n",
    "\n",
    "# 1. Save the Model Pipeline (Brain + Translator)\n",
    "joblib.dump(final_production_pipeline, model_path)\n",
    "\n",
    "# 2. Save the Column List (The Alignment Key)\n",
    "# This is required so the API knows how to create the NaN columns\n",
    "cols_filename = 'models/ames_model_columns.pkl'\n",
    "joblib.dump(X_train.columns.tolist(), cols_path)\n",
    "\n",
    "print(f\"âœ… Model saved to:   {model_path}\")\n",
    "print(f\"âœ… Columns saved to: {cols_path}\")\n",
    "print(f\"   You can now restart app_3.0.py\")\n",
    "\n",
    "# ==========================================\n",
    "# 7. PRODUCTION SIMULATION (Inference)\n",
    "# ==========================================\n",
    "print(\"\\n--- Simulating Production Inference ---\")\n",
    "\n",
    "# 1. THE USER INPUT (Partial Data)\n",
    "user_input = {\n",
    "    \"Neighborhood\": \"CollgCr\",\n",
    "    \"LotArea\": 9600,\n",
    "    \"OverallQual\": 7,\n",
    "    \"YearBuilt\": 2000,\n",
    "    \"GrLivArea\": 1700,\n",
    "    # Missing: GarageCars, KitchenQual, etc.\n",
    "}\n",
    "\n",
    "# 2. CREATE DATAFRAME\n",
    "input_df = pd.DataFrame([user_input])\n",
    "\n",
    "# 3. THE BRIDGE (Crucial Alignment Step)\n",
    "# Load the columns we just saved (simulating a real API restart)\n",
    "expected_cols = joblib.load(cols_filename)\n",
    "\n",
    "# Force input to match training structure (add missing cols as NaN)\n",
    "input_df = input_df.reindex(columns=expected_cols)\n",
    "\n",
    "# 4. PREDICT\n",
    "# The pipeline handles the NaNs using the internal SimpleImputer\n",
    "pred_price = final_production_pipeline.predict(input_df)[0]\n",
    "\n",
    "print(f\"Input: {user_input}\")\n",
    "print(f\"Predicted Price: ${pred_price:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files to: /Users/ozkangelincik/git_proj/ames-housing-prices/models ...\n",
      "âœ… Options Saved (ames_model_options.pkl)\n",
      "\n",
      "ðŸš€ READY! Re-run the dashboard now.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# FINAL SAVE: Correct Path & All Files (Fixed)\n",
    "# ==========================================\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Define Root\n",
    "project_root = Path.cwd().parent.resolve()\n",
    "MODELS_DIR = project_root / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Calculate Defaults (For Math/Imputation)\n",
    "train_defaults = {}\n",
    "for col in X_train.columns:\n",
    "    if col in CATEGORICAL_COLS:\n",
    "        # Use mode[0] to get the single most frequent value\n",
    "        # Ensure we handle empty modes just in case\n",
    "        modes = X_train[col].mode()\n",
    "        train_defaults[col] = modes[0] if not modes.empty else \"None\"\n",
    "    else:\n",
    "        train_defaults[col] = X_train[col].median()\n",
    "\n",
    "# 3. Calculate Unique Options (For Dashboard Dropdowns!)\n",
    "#    This extracts every unique value seen in the training set\n",
    "unique_options = {}\n",
    "for col in X_train.columns:\n",
    "    if col in CATEGORICAL_COLS:\n",
    "        # FIX IS HERE: .astype(str) ensures NaNs become \"nan\" strings, preventing the crash\n",
    "        unique_vals = X_train[col].astype(str).unique().tolist()\n",
    "        unique_options[col] = sorted(unique_vals)\n",
    "\n",
    "# 4. Save EVERYTHING\n",
    "print(f\"Saving files to: {MODELS_DIR} ...\")\n",
    "\n",
    "# A. The Model\n",
    "joblib.dump(final_production_pipeline, MODELS_DIR / 'ames_housing_super_model_production.pkl')\n",
    "\n",
    "# B. The Columns\n",
    "joblib.dump(X_train.columns.tolist(), MODELS_DIR / 'ames_model_columns.pkl')\n",
    "\n",
    "# C. The Defaults (For Math)\n",
    "joblib.dump(train_defaults, MODELS_DIR / 'ames_model_defaults.pkl')\n",
    "\n",
    "# D. The Options (For Dropdowns)\n",
    "joblib.dump(unique_options, MODELS_DIR / 'ames_model_options.pkl')\n",
    "print(\"âœ… Options Saved (ames_model_options.pkl)\")\n",
    "\n",
    "print(\"\\nðŸš€ READY! Re-run the dashboard now.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ames-housing-prices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
